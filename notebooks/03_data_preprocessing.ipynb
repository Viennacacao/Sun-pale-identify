{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/raw/images\n",
      "Training set images shape: (2267, 300, 300, 3)\n",
      "Test set images shape: (756, 300, 300, 3)\n",
      "Training set labels shape: (2267, 4)\n",
      "Test set labels shape: (756, 4)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Data processed for CNN and SVM models\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set data directory path\n",
    "data_dir = '../data/raw/'\n",
    "images_dir = os.path.join(data_dir, 'images')\n",
    "print(images_dir)\n",
    "labels_path = os.path.join(data_dir, 'labels_agu.csv')\n",
    "\n",
    "# Read label data\n",
    "labels_df = pd.read_csv(labels_path, names=['image_id', 'probability', 'type'], sep='\\s+')\n",
    "# 映射概率到类别\n",
    "def map_probability_to_class(probability):\n",
    "    if probability == 0.0:\n",
    "        return 0\n",
    "    elif 0.33 <= probability < 0.4:\n",
    "        return 1\n",
    "    elif 0.66 <= probability < 0.68:\n",
    "        return 2\n",
    "    elif probability == 1.0:\n",
    "        return 3\n",
    "    else:\n",
    "        raise ValueError(f\"未知的概率值: {probability}\")\n",
    "\n",
    "labels_df['class'] = labels_df['probability'].apply(map_probability_to_class)\n",
    "\n",
    "def load_images(image_paths, image_dir):\n",
    "    images = []\n",
    "    for image_path in image_paths:\n",
    "        full_path = os.path.join(image_dir, image_path)\n",
    "        with Image.open(full_path) as img:\n",
    "            img_array = np.array(img) / 255.0  # Normalize pixel values to [0, 1]\n",
    "            if img_array.ndim == 2:\n",
    "                # If the image is grayscale, convert it to a three-channel grayscale image\n",
    "                img_array = np.stack((img_array,)*3, axis=-1)\n",
    "            images.append(img_array)\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "image_paths = labels_df['image_id'].tolist()\n",
    "images = load_images(image_paths, data_dir)\n",
    "\n",
    "# Ensure images have one channel\n",
    "if images.ndim == 3:\n",
    "    images = np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Convert class labels to one-hot encoding\n",
    "labels = to_categorical(labels_df['class'].values, num_classes=4)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    images, labels, test_size=0.25, stratify=labels, random_state=42,shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "# Save split dataset to files\n",
    "np.save('../data/processed/X_train_cs.npy', X_train)\n",
    "np.save('../data/processed/X_test_cs.npy', X_test)\n",
    "np.save('../data/processed/y_train_cs.npy', y_train)\n",
    "np.save('../data/processed/y_test_cs.npy', y_test)\n",
    "\n",
    "# Confirm saved data\n",
    "print(f\"Training set images shape: {X_train.shape}\")\n",
    "print(f\"Test set images shape: {X_test.shape}\")\n",
    "print(f\"Training set labels shape: {y_train.shape}\")\n",
    "print(f\"Test set labels shape: {y_test.shape}\")\n",
    "# Apply stratified sampling to ensure consistency in class distribution between training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set images shape: (2267, 300, 300, 3)\n",
      "Test set images shape: (756, 300, 300, 3)\n",
      "Training set labels shape: (2267, 4)\n",
      "Test set labels shape: (756, 4)\n",
      "Training set types shape: (2267, 1)\n",
      "Test set types shape: (756, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Data_types processed for CNN and SVM models\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "import cv2\n",
    "from skimage import filters\n",
    "\n",
    "\n",
    "# Path setup\n",
    "data_dir = '../data/raw'\n",
    "labels_file = '../data/raw/labels_agu.csv'\n",
    "\n",
    "# Load label file and specify column names\n",
    "labels_df = pd.read_csv(labels_file, names=['image_id', 'probability', 'type'], sep='\\s+')\n",
    "labels_df['class'] = labels_df['probability'].apply(map_probability_to_class)\n",
    "\n",
    "# Map probabilities to classes\n",
    "def map_probability_to_class(probability):\n",
    "    # Map probabilities to classes\n",
    "    if probability == 0.0:\n",
    "        return 0\n",
    "    elif probability == 0.33:\n",
    "        return 1\n",
    "    elif probability == 0.67:\n",
    "        return 2\n",
    "    elif probability == 1.0:\n",
    "        return 3\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown probability value: {probability}\")\n",
    "\n",
    "\n",
    "\n",
    "def convert_color_space(image, target_space):\n",
    "    # Convert color space of the image\n",
    "    if target_space == 'HSV':\n",
    "        converted_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    elif target_space == 'LAB':\n",
    "        converted_image = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown target_space: {target_space}\")\n",
    "    return converted_image\n",
    "\n",
    "def edge_enhancement(image):\n",
    "    # Convert image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    gray_image = np.uint8(gray_image)\n",
    "    # Edge detection using Canny algorithm\n",
    "    edges = cv2.Canny(gray_image, 300, 300)\n",
    "    # Convert single channel edge image to three channels\n",
    "    edges_colored = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\n",
    "    # Convert edge image to same data type as original image (if needed)\n",
    "    if edges_colored.dtype != image.dtype:\n",
    "        edges_colored = edges_colored.astype(image.dtype)\n",
    "\n",
    "    # Blend images\n",
    "    enhanced_image = cv2.addWeighted(image, 0.8, edges_colored, 0.2, 0)\n",
    "    \n",
    "    return enhanced_image\n",
    "\n",
    "def load_images(image_paths, image_dir):\n",
    "    images = []\n",
    "    for image_path in image_paths:\n",
    "        full_path = os.path.join(image_dir, image_path)\n",
    "        with Image.open(full_path) as img:\n",
    "            img_array = np.array(img) / 255.0  # Normalize pixel values to [0, 1]\n",
    "            if img_array.ndim == 2:\n",
    "                # If the image is grayscale, convert it to a three-channel grayscale image\n",
    "                img_array = np.stack((img_array,)*3, axis=-1)\n",
    "            images.append(img_array)\n",
    "    return np.array(images)\n",
    "\n",
    "def preprocess_image_for_transformer(image_path, image_type, target_size=(300, 300)):\n",
    "    # Load image file\n",
    "    image = load_img(image_path, target_size=target_size)\n",
    "    # Convert it to array\n",
    "    image = img_to_array(image)\n",
    "    # Apply different preprocessing based on image type\n",
    "    if image_type == 0 :  # Assume 0 represents \"mono\"\n",
    "        # Apply specific preprocessing for \"mono\" type images\n",
    "        image = convert_color_space(image, 'HSV')\n",
    "        # Enhance edges using Sobel operator\n",
    "        image = edge_enhancement(image)\n",
    "        # Contrast enhancement - CLAHE\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        for i in range(image.shape[-1]):\n",
    "            image[..., i] = clahe.apply(image[..., i].astype('uint8'))\n",
    "        # Noise reduction - Gaussian Blur\n",
    "        image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "        # pass\n",
    "        \n",
    "    elif image_type == 0:  # Assume 1 represents \"poly\"\n",
    "        # pass\n",
    "        # Apply specific preprocessing for \"poly\" type images\n",
    "        image = convert_color_space(image, 'LAB')\n",
    "        # Edge detection in x direction\n",
    "        sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=5)\n",
    "        # Edge detection in y direction\n",
    "        sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)\n",
    "        # Compute absolute values\n",
    "        abs_sobelx = np.absolute(sobelx)\n",
    "        abs_sobely = np.absolute(sobely)\n",
    "        # Combine Sobel x and y\n",
    "        sobel_combined = np.sqrt(np.square(abs_sobelx) + np.square(abs_sobely))\n",
    "        sobel_combined = np.clip(sobel_combined, 0, 255).astype('uint8')\n",
    "        image = sobel_combined\n",
    "        # Contrast enhancement - CLAHE\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        for i in range(image.shape[-1]):\n",
    "            image[..., i] = clahe.apply(image[..., i].astype('uint8'))\n",
    "\n",
    "    image = np.array(image) / 255.0  # Normalize pixel values to [0, 1]\n",
    "    # Normalize pixel values\n",
    "    return image\n",
    "\n",
    "\n",
    "# image_paths = labels_df['image_id'].tolist()\n",
    "# images = load_images(image_paths, data_dir)\n",
    "image_paths = labels_df['image_id'].apply(lambda x: os.path.join(data_dir, x))\n",
    "\n",
    "# Ensure images have one channel\n",
    "if images.ndim == 3:\n",
    "    images = np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "type_label_encoder = LabelEncoder()\n",
    "\n",
    "# Convert type labels to integer form\n",
    "types_encoded = type_label_encoder.fit_transform(labels_df['type'].values)\n",
    "# Now types_encoded contains integer labels for type information, which can be used as one of the inputs for the model\n",
    "\n",
    "# Convert type labels to integers\n",
    "types_encoded = types_encoded.reshape(-1, 1)  # Reshape to (num_samples, 1)\n",
    "\n",
    "# Use a list comprehension to preprocess all images and include type information\n",
    "X = np.array([preprocess_image_for_transformer(path, types_encoded[idx][0]) for idx, path in enumerate(image_paths)])\n",
    "\n",
    "y_one_hot = to_categorical(labels_df['class'].values, num_classes=4)\n",
    "\n",
    "# Stratify split dataset by types\n",
    "X_train, X_test, y_train, y_test, types_train, types_test = train_test_split(\n",
    "    X, y_one_hot, types_encoded, test_size=0.25, stratify=types_encoded, random_state=42,shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "# 保存分割后的数据集到文件\n",
    "np.save('../data/processed/X_train_cs_type_pc.npy', X_train)\n",
    "np.save('../data/processed/X_test_cs_type_pc.npy', X_test)\n",
    "np.save('../data/processed/y_train_cs_type_pc.npy', y_train)\n",
    "np.save('../data/processed/y_test_cs_type_pc.npy', y_test)\n",
    "np.save('../data/processed/types_train_cs_type_pc.npy', types_train)\n",
    "np.save('../data/processed/types_test_cs_type_pc.npy', types_test)\n",
    "\n",
    "# 确认已保存的数据\n",
    "print(f\"Training set images shape: {X_train.shape}\")\n",
    "print(f\"Test set images shape: {X_test.shape}\")\n",
    "print(f\"Training set labels shape: {y_train.shape}\")\n",
    "print(f\"Test set labels shape: {y_test.shape}\")\n",
    "print(f\"Training set types shape: {types_train.shape}\")\n",
    "print(f\"Test set types shape: {types_test.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Normal transformer data processed\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import cv2\n",
    "from IPython.display import display\n",
    "\n",
    "def preprocess_image_for_transformer(image_path, size=(300, 300), num_patches=16):\n",
    "   # Load image and resize\n",
    "   image = load_img(image_path, target_size=size, color_mode='rgb')\n",
    "   image = img_to_array(image)\n",
    "\n",
    "   # Add other necessary image preprocessing steps here\n",
    "   # Contrast enhancement - CLAHE\n",
    "   clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "   for i in range(image.shape[-1]):\n",
    "       image[..., i] = clahe.apply(image[..., i].astype('uint8'))\n",
    "   # Noise reduction - Gaussian blur\n",
    "   image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "   # Normalize pixel values\n",
    "   image = image / 255.0\n",
    "   return image\n",
    "\n",
    "# Set data directory path and labels file\n",
    "data_dir = '../data/raw'\n",
    "labels_file = '../data/raw/labels.csv'\n",
    "\n",
    "# Read labels file and check column names\n",
    "labels_df = pd.read_csv(labels_file)\n",
    "print(labels_df.head())\n",
    "\n",
    "# Read labels file and specify column names\n",
    "labels_df = pd.read_csv(labels_file, names=['image_id', 'probability', 'type'], sep='\\s+')\n",
    "\n",
    "image_paths = labels_df['image_id'].apply(lambda x: os.path.join(data_dir, x))\n",
    "labels = labels_df['probability'].values\n",
    "\n",
    "# Preprocess images\n",
    "X = np.array([preprocess_image_for_transformer(path) for path in image_paths])\n",
    "y = np.array(labels)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y = to_categorical(y, num_classes=4)\n",
    "print(y[:50])\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "   X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "print(y_test.shape)\n",
    "\n",
    "# Save preprocessed data to files\n",
    "np.save('../data/processed/X_train_transformer.npy', X_train)\n",
    "np.save('../data/processed/X_test_transformer.npy', X_test)\n",
    "np.save('../data/processed/y_train_transformer.npy', y_train)\n",
    "np.save('../data/processed/y_test_transformer.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save split dataset_types to file\n",
    "np.save('../data/processed/X_train_transformer_types.npy', X_train)\n",
    "np.save('../data/processed/X_test_transformer_types.npy', X_test)\n",
    "np.save('../data/processed/y_train_transformer_types.npy', y_train)\n",
    "np.save('../data/processed/y_test_transformer_types.npy', y_test)\n",
    "np.save('../data/processed/types_train.npy', types_train)\n",
    "np.save('../data/processed/types_test.npy', types_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Data_augmention types classify model transformer\n",
    "\"\"\"\n",
    "import os\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "import cv2\n",
    "from skimage import filters\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def convert_color_space(image, target_space):\n",
    "    # Convert color space of the image\n",
    "    if target_space == 'HSV':\n",
    "        converted_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    elif target_space == 'LAB':\n",
    "        converted_image = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown target_space: {target_space}\")\n",
    "    return converted_image\n",
    "\n",
    "def edge_enhancement(image):\n",
    "    # Convert image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    gray_image = np.uint8(gray_image)\n",
    "    # Edge detection using Canny algorithm\n",
    "    edges = cv2.Canny(gray_image, 300, 300)\n",
    "    # Convert single channel edge image to three channels\n",
    "    edges_colored = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\n",
    "    # Convert edge image to same data type as original image (if needed)\n",
    "    if edges_colored.dtype != image.dtype:\n",
    "        edges_colored = edges_colored.astype(image.dtype)\n",
    "\n",
    "    # Blend images\n",
    "    enhanced_image = cv2.addWeighted(image, 0.8, edges_colored, 0.2, 0)\n",
    "    \n",
    "    return enhanced_image\n",
    "\n",
    "\n",
    "def preprocess_image_for_transformer(image_path, image_type, target_size=(300, 300)):\n",
    "    # Load image file\n",
    "    image = load_img(image_path, target_size=target_size)\n",
    "    # Convert it to array\n",
    "    image = img_to_array(image)\n",
    "    # Apply different preprocessing based on image type\n",
    "    if image_type == 0 :  # Assume 0 represents \"mono\"\n",
    "        # Apply specific preprocessing for \"mono\" type images\n",
    "        image = convert_color_space(image, 'HSV')\n",
    "        # Enhance edges using Sobel operator\n",
    "        image = edge_enhancement(image)\n",
    "        # Contrast enhancement - CLAHE\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        for i in range(image.shape[-1]):\n",
    "            image[..., i] = clahe.apply(image[..., i].astype('uint8'))\n",
    "        # Noise reduction - Gaussian Blur\n",
    "        image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "        \n",
    "    elif image_type == 0:  # Assume 1 represents \"poly\"\n",
    "        # Apply specific preprocessing for \"poly\" type images\n",
    "        image = convert_color_space(image, 'LAB')\n",
    "        # Edge detection in x direction\n",
    "        sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=5)\n",
    "        # Edge detection in y direction\n",
    "        sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)\n",
    "        # Compute absolute values\n",
    "        abs_sobelx = np.absolute(sobelx)\n",
    "        abs_sobely = np.absolute(sobely)\n",
    "        # Combine Sobel x and y\n",
    "        sobel_combined = np.sqrt(np.square(abs_sobelx) + np.square(abs_sobely))\n",
    "        sobel_combined = np.clip(sobel_combined, 0, 255).astype('uint8')\n",
    "        image = sobel_combined\n",
    "        # Contrast enhancement - CLAHE\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        for i in range(image.shape[-1]):\n",
    "            image[..., i] = clahe.apply(image[..., i].astype('uint8'))\n",
    "\n",
    "    # Preprocess image for EfficientNetB0\n",
    "    image = preprocess_input(image)\n",
    "    # Normalize pixel values\n",
    "    return image\n",
    "\n",
    "\n",
    "# Map probabilities to classes\n",
    "def map_probability_to_class(probability):\n",
    "    # Map probabilities to classes\n",
    "    if probability == 0.0:\n",
    "        return 0\n",
    "    elif probability == 0.33:\n",
    "        return 1\n",
    "    elif probability == 0.67:\n",
    "        return 2\n",
    "    elif probability == 1.0:\n",
    "        return 3\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown probability value: {probability}\")\n",
    "    \n",
    "\n",
    "# Path setup\n",
    "data_dir = '../data/raw'\n",
    "labels_file = '../data/raw/labels_agu.csv'\n",
    "\n",
    "# Load label file and specify column names\n",
    "labels_df = pd.read_csv(labels_file, names=['image_id', 'probability', 'type'], sep='\\s+')\n",
    "image_paths = labels_df['image_id'].apply(lambda x: os.path.join(data_dir, x))\n",
    "\n",
    "labels_df['class'] = labels_df['probability'].apply(map_probability_to_class)\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "type_label_encoder = LabelEncoder()\n",
    "\n",
    "# Convert type labels to integer form\n",
    "types_encoded = type_label_encoder.fit_transform(labels_df['type'].values)\n",
    "# Now types_encoded contains integer labels for type information, which can be used as one of the inputs for the model\n",
    "\n",
    "# Convert type labels to integers\n",
    "types_encoded = types_encoded.reshape(-1, 1)  # Reshape to (num_samples, 1)\n",
    "\n",
    "# Use a list comprehension to preprocess all images and include type information\n",
    "X = np.array([preprocess_image_for_transformer(path, types_encoded[idx][0]) for idx, path in enumerate(image_paths)])\n",
    "\n",
    "# Convert class labels to one-hot encoding\n",
    "y_one_hot = to_categorical(labels_df['class'].values, num_classes=4)\n",
    "\n",
    "# Stratify split dataset by types\n",
    "X_train, X_test, y_train, y_test, types_train, types_test = train_test_split(\n",
    "    X, y_one_hot, types_encoded, test_size=0.25, stratify=types_encoded, random_state=42,shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "# Save split dataset_types to file\n",
    "np.save('../data/processed/X_train_transformer_types_aug.npy', X_train)\n",
    "np.save('../data/processed/X_test_transformer_types_aug.npy', X_test)\n",
    "np.save('../data/processed/y_train_transformer_types_aug.npy', y_train)\n",
    "np.save('../data/processed/y_test_transformer_types_aug.npy', y_test)\n",
    "np.save('../data/processed/types_train_aug.npy', types_train)\n",
    "np.save('../data/processed/types_test_aug.npy', types_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set images shape: (2267, 300, 300, 3)\n",
      "Test set images shape: (756, 300, 300, 3)\n",
      "Training set labels shape: (2267, 4)\n",
      "Test set labels shape: (756, 4)\n",
      "Training set types shape: (2267, 1)\n",
      "Test set types shape: (756, 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# Set the path to the dataset\n",
    "base_path = os.path.dirname(os.getcwd()) \n",
    "model_path = os.path.join(base_path, 'models/transformer_with_type_aug_model.h5') \n",
    "\n",
    "X_test = np.load('../data/processed/X_test_transformer_types_aug.npy')\n",
    "y_test = np.load('../data/processed/y_test_transformer_types_aug.npy')\n",
    "types_test = np.load('../data/processed/types_test_aug.npy')\n",
    "\n",
    "print(f\"Training set images shape: {X_train.shape}\")\n",
    "print(f\"Test set images shape: {X_test.shape}\")\n",
    "print(f\"Training set labels shape: {y_train.shape}\")\n",
    "print(f\"Test set labels shape: {y_test.shape}\")\n",
    "print(f\"Training set types shape: {types_train.shape}\")\n",
    "print(f\"Test set types shape: {types_test.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ca_tfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
