{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "57/57 [==============================] - 104s 2s/step - loss: 2.2517 - accuracy: 0.4343 - val_loss: 1.0859 - val_accuracy: 0.6079\n",
      "Epoch 2/5\n",
      "57/57 [==============================] - 96s 2s/step - loss: 1.1197 - accuracy: 0.5539 - val_loss: 0.9514 - val_accuracy: 0.6806\n",
      "Epoch 3/5\n",
      "57/57 [==============================] - 92s 2s/step - loss: 0.9393 - accuracy: 0.6644 - val_loss: 0.8632 - val_accuracy: 0.6762\n",
      "Epoch 4/5\n",
      "57/57 [==============================] - 92s 2s/step - loss: 0.8821 - accuracy: 0.6649 - val_loss: 0.8661 - val_accuracy: 0.6916\n",
      "Epoch 5/5\n",
      "57/57 [==============================] - 93s 2s/step - loss: 0.8101 - accuracy: 0.7261 - val_loss: 0.7631 - val_accuracy: 0.7269\n"
     ]
    }
   ],
   "source": [
    "\"\"\"CNN model training\n",
    "\"\"\"\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Set directory path for test data\n",
    "data_dir = '../data/processed/'\n",
    "\n",
    "# Load test data\n",
    "X_train = np.load(data_dir + 'X_train_cs.npy')\n",
    "y_train = np.load(data_dir + 'y_train_cs.npy', allow_pickle=True)\n",
    "\n",
    "# Build CNN model\n",
    "model_cnn = Sequential([\n",
    "   Conv2D(32, (3, 3), activation='relu', input_shape=(300, 300, 3)),\n",
    "   MaxPooling2D((2, 2)),\n",
    "   Conv2D(64, (3, 3), activation='relu'),\n",
    "   MaxPooling2D((2, 2)),\n",
    "   Conv2D(128, (3, 3), activation='relu'),\n",
    "   MaxPooling2D((2, 2)),\n",
    "   Flatten(),\n",
    "   Dense(512, activation='relu'),\n",
    "   Dropout(0.5),\n",
    "   Dense(4, activation='softmax')  # Four outputs for four-class problem\n",
    "])\n",
    "\n",
    "model_cnn.compile(optimizer='adam',\n",
    "                 loss='categorical_crossentropy',  # Loss function for multi-class classification\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Optional: Add early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Train CNN model\n",
    "history = model_cnn.fit(\n",
    "   X_train, y_train,\n",
    "   epochs=5,  # Number of epochs or the number of times the model sees the data\n",
    "   batch_size=32,\n",
    "   validation_split=0.2,  # Use 20% of the data for validation\n",
    "   callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Save trained model\n",
    "model_cnn.save('../models/cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(756, 1)\n",
      "Epoch 1/10\n",
      "71/71 [==============================] - 122s 2s/step - loss: 2.1720 - accuracy: 0.4596 - val_loss: 1.1295 - val_accuracy: 0.4987\n",
      "Epoch 2/10\n",
      "71/71 [==============================] - 116s 2s/step - loss: 1.0539 - accuracy: 0.5729 - val_loss: 0.9000 - val_accuracy: 0.6587\n",
      "Epoch 3/10\n",
      "71/71 [==============================] - 115s 2s/step - loss: 0.8521 - accuracy: 0.6973 - val_loss: 0.8252 - val_accuracy: 0.7037\n",
      "Epoch 4/10\n",
      "71/71 [==============================] - 116s 2s/step - loss: 0.7678 - accuracy: 0.7254 - val_loss: 0.7978 - val_accuracy: 0.7156\n",
      "Epoch 5/10\n",
      "71/71 [==============================] - 118s 2s/step - loss: 0.7714 - accuracy: 0.7177 - val_loss: 0.7579 - val_accuracy: 0.7328\n",
      "Epoch 6/10\n",
      "71/71 [==============================] - 123s 2s/step - loss: 0.7210 - accuracy: 0.7385 - val_loss: 0.7660 - val_accuracy: 0.7328\n",
      "Epoch 7/10\n",
      "71/71 [==============================] - 120s 2s/step - loss: 0.6764 - accuracy: 0.7674 - val_loss: 0.7781 - val_accuracy: 0.7183\n",
      "Epoch 8/10\n",
      "71/71 [==============================] - 117s 2s/step - loss: 0.7105 - accuracy: 0.7470 - val_loss: 0.7421 - val_accuracy: 0.7381\n",
      "Epoch 9/10\n",
      "71/71 [==============================] - 117s 2s/step - loss: 0.6747 - accuracy: 0.7459 - val_loss: 0.7785 - val_accuracy: 0.7262\n",
      "Epoch 10/10\n",
      "71/71 [==============================] - 111s 2s/step - loss: 0.6952 - accuracy: 0.7573 - val_loss: 0.7479 - val_accuracy: 0.7394\n"
     ]
    }
   ],
   "source": [
    "\"\"\"cnn_types train \"\"\"\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, concatenate, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Set directory path for processed data\n",
    "data_dir = '../data/processed/'\n",
    "\n",
    "# Load processed data\n",
    "X_train_images = np.load(data_dir + 'X_train_cs_type_pc.npy')\n",
    "types_train = np.load(data_dir + 'types_train_cs_type_pc.npy')\n",
    "y_train = np.load(data_dir + 'y_train_cs_type_pc.npy')\n",
    "\n",
    "X_test_images = np.load(data_dir + 'X_test_cs_type_pc.npy')\n",
    "types_test = np.load(data_dir + 'types_test_cs_type_pc.npy')\n",
    "y_test = np.load(data_dir + 'y_test_cs_type_pc.npy')\n",
    "\n",
    "\n",
    "# Assuming `types_train` and `types_test` are already integer encoded\n",
    "num_types = np.max(types_train) + 1  # Assuming types are 0-indexed\n",
    "\n",
    "# Build CNN model\n",
    "image_input = Input(shape=(300, 300, 3), name='image_input')\n",
    "x = Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Type input\n",
    "type_input = Input(shape=(1,), name='type_input')\n",
    "type_embedding = Dense(8, activation='relu')(type_input)\n",
    "\n",
    "# Concatenate image and type features\n",
    "combined_features = concatenate([x, type_embedding])\n",
    "\n",
    "# Dense layers\n",
    "z = Dense(512, activation='relu')(combined_features)\n",
    "z = Dropout(0.5)(z)\n",
    "output = Dense(4, activation='softmax')(z)\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=[image_input, type_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Reshape types to be compatible with Dense layer input\n",
    "types_train_reshaped = types_train.reshape(-1, 1)\n",
    "types_test_reshaped = types_test.reshape(-1, 1)\n",
    "\n",
    "print(types_test_reshaped.shape)\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    [X_train_images, types_train_reshaped],\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    validation_data=\n",
    "    ([X_test_images, types_test_reshaped], y_test)\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save('../models/cnn_multi_input_pc_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SVM model training \"\"\"\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Set the directory path for the split data\n",
    "data_dir = Path('../data/processed/')  # This path is relative to the 'notebooks' directory\n",
    "\n",
    "# Ensure the path is correct\n",
    "assert data_dir.exists(), f\"Path does not exist: {data_dir}\"\n",
    "\n",
    "# Load the data\n",
    "X_train = np.load(data_dir / 'X_train.npy')\n",
    "X_test = np.load(data_dir / 'X_test.npy')\n",
    "y_train = np.load(data_dir / 'y_train.npy', allow_pickle=True)\n",
    "y_test = np.load(data_dir / 'y_test.npy', allow_pickle=True)\n",
    "\n",
    "# Flatten the image data to fit the SVM classifier\n",
    "X_train_flat = X_train.reshape((X_train.shape[0], -1))\n",
    "\n",
    "# Create an SVM classifier instance\n",
    "svc = svm.SVC(kernel='rbf', class_weight='balanced', probability=True)\n",
    "\n",
    "# Perform PCA dimensionality reduction to reduce the computational complexity\n",
    "pca = PCA(n_components=150, whiten=True, random_state=42)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create a pipeline that includes normalization, PCA, and SVM\n",
    "pipeline_svm = Pipeline([\n",
    "   ('scaler', scaler),\n",
    "   ('pca', pca),\n",
    "   ('svc', svc)\n",
    "])\n",
    "\n",
    "# Convert one-hot encoded labels to integer class labels\n",
    "y_train_labels = np.argmax(y_train, axis=1)\n",
    "\n",
    "# Train the model\n",
    "pipeline_svm.fit(X_train_flat, y_train_labels)\n",
    "\n",
    "# The model can now be used for prediction or further evaluation\n",
    "\n",
    "# Save the SVM model\n",
    "import joblib\n",
    "joblib.dump(pipeline_svm, '../models/svm_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Normal Transformer model train \"\"\"\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import EfficientNetB0  # Using EfficientNet as the feature extractor\n",
    "from tensorflow.keras.layers import LayerNormalization, MultiHeadAttention, Add, Embedding\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Reshape\n",
    "from tensorflow.keras.layers import LayerNormalization, MultiHeadAttention, Dropout, Add\n",
    "from tensorflow.keras.layers import Flatten, GlobalAveragePooling1D\n",
    "import numpy as np\n",
    "\n",
    "# Set the directory path for the data\n",
    "data_dir = '../data/processed/'\n",
    "\n",
    "# Load the training data\n",
    "X_train_transformer = np.load(data_dir + 'X_train_transformer2.npy')\n",
    "y_train_transformer = np.load(data_dir + 'y_train_transformer2.npy', allow_pickle=True)\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "   # Multi-head self-attention (MHA) layer\n",
    "   x = MultiHeadAttention(\n",
    "       key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "   )(inputs, inputs)\n",
    "   x = Dropout(dropout)(x)\n",
    "   x = Add()([x, inputs])\n",
    "\n",
    "   # Feed forward network (FFN)\n",
    "   x = Dense(ff_dim, activation=\"relu\")(x)\n",
    "   x = Dropout(dropout)(x)\n",
    "   x = Dense(inputs.shape[-1])(x)\n",
    "   x = Add()([x, inputs])\n",
    "\n",
    "   # Layer normalization\n",
    "   x = LayerNormalization(epsilon=1e-6)(x)\n",
    "   return x\n",
    "\n",
    "def build_transformer_model(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout=0, mlp_dropout=0):\n",
    "   inputs = Input(shape=input_shape)\n",
    "   efficientnet = EfficientNetB0(include_top=False, input_tensor=inputs, weights=\"imagenet\")\n",
    "   efficientnet.trainable = False\n",
    "\n",
    "   # Use GlobalAveragePooling2D to reduce dimensionality\n",
    "   x = GlobalAveragePooling2D()(efficientnet.output)\n",
    "   x = Reshape((-1, x.shape[-1]))(x)  # Convert to a 2D sequence\n",
    "\n",
    "   # Transformer encoder\n",
    "   for _ in range(num_transformer_blocks):\n",
    "       x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "   # After the Transformer, use GlobalAveragePooling1D to flatten the features or use Flatten()\n",
    "   x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "   # MLP head\n",
    "   for dim in mlp_units:\n",
    "       x = Dense(dim, activation=\"relu\")(x)\n",
    "       x = Dropout(mlp_dropout)(x)\n",
    "\n",
    "   # Output layer\n",
    "   outputs = Dense(4, activation=\"softmax\")(x)\n",
    "   model = Model(inputs, outputs)\n",
    "   return model\n",
    "\n",
    "\n",
    "input_shape = (300, 300, 3)  # Adjust to match the actual image size and channel count\n",
    "head_size = 256\n",
    "num_heads = 4\n",
    "ff_dim = 4\n",
    "num_transformer_blocks = 4\n",
    "mlp_units = [128]\n",
    "dropout = 0.1\n",
    "mlp_dropout = 0.1\n",
    "\n",
    "\n",
    "# Build the model\n",
    "model = build_transformer_model(\n",
    "   input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout, mlp_dropout\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "# model.summary()\n",
    "\n",
    "# train Transformer model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=32,\n",
    "    epochs=10,  # 根据需要调整epochs数量\n",
    "    validation_split=0.25,  # 保留20%的数据用作验证集\n",
    "    shuffle=True  # 打乱数据\n",
    ")\n",
    "\n",
    "\n",
    "# save model \n",
    "model.save('../models/transformer_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape before squeeze: (2267, 4)\n",
      "y_train shape after squeeze: (2267, 4)\n",
      "Epoch 1/8\n",
      "57/57 [==============================] - 147s 2s/step - loss: 6.8995 - accuracy: 0.3733 - val_loss: 1.0680 - val_accuracy: 0.5419\n",
      "Epoch 2/8\n",
      "57/57 [==============================] - 120s 2s/step - loss: 1.0048 - accuracy: 0.5846 - val_loss: 0.9588 - val_accuracy: 0.6784\n",
      "Epoch 3/8\n",
      "57/57 [==============================] - 127s 2s/step - loss: 0.9495 - accuracy: 0.6442 - val_loss: 0.7477 - val_accuracy: 0.7445\n",
      "Epoch 4/8\n",
      "57/57 [==============================] - 126s 2s/step - loss: 0.9019 - accuracy: 0.6706 - val_loss: 0.7261 - val_accuracy: 0.7379\n",
      "Epoch 5/8\n",
      "57/57 [==============================] - 129s 2s/step - loss: 0.8175 - accuracy: 0.7040 - val_loss: 0.6854 - val_accuracy: 0.7599\n",
      "Epoch 6/8\n",
      "57/57 [==============================] - 124s 2s/step - loss: 0.9291 - accuracy: 0.6626 - val_loss: 0.6657 - val_accuracy: 0.7775\n",
      "Epoch 7/8\n",
      "57/57 [==============================] - 127s 2s/step - loss: 0.7914 - accuracy: 0.7076 - val_loss: 0.7257 - val_accuracy: 0.7621\n",
      "Epoch 8/8\n",
      "57/57 [==============================] - 126s 2s/step - loss: 0.8002 - accuracy: 0.7188 - val_loss: 0.6312 - val_accuracy: 0.7797\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"image_types processed transformer train \"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Concatenate, Embedding, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import LayerNormalization, MultiHeadAttention, Add, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Reshape\n",
    "\n",
    "# Data path\n",
    "data_dir = '../data/processed/'\n",
    "labels_file = '../data/raw/labels6.csv'\n",
    "\n",
    "# Load data\n",
    "X_train = np.load(data_dir + 'X_train_transformer_types_aug.npy')\n",
    "y_train = np.load(data_dir + 'y_train_transformer_types_aug.npy')\n",
    "labels_df = pd.read_csv(labels_file, names=['image_id', 'probability', 'type'], sep='\\s+')\n",
    "types = labels_df['type'].values\n",
    "\n",
    "# Adjust y_train shape if incorrect\n",
    "# Check shape of y_train\n",
    "print(\"y_train shape before squeeze:\", y_train.shape)\n",
    "\n",
    "# If y_train's second dimension is 1, remove it using np.squeeze\n",
    "if y_train.shape[1] == 1:\n",
    "    y_train = np.squeeze(y_train, axis=1)\n",
    "\n",
    "print(\"y_train shape after squeeze:\", y_train.shape)\n",
    "\n",
    "# Encode type labels\n",
    "label_encoder = LabelEncoder()\n",
    "types_encoded = label_encoder.fit_transform(types)\n",
    "num_types = len(np.unique(types_encoded))  # Get the number of unique types\n",
    "\n",
    "# Convert type labels to one-hot encoding\n",
    "types_train_one_hot = to_categorical(types_encoded)\n",
    "\n",
    "# Definition of Transformer encoder layer\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    x = LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    attention_output = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "    x = Add()([attention_output, inputs])\n",
    "    x = LayerNormalization(epsilon=1e-6)(x)\n",
    "    ff_output = Dense(ff_dim, activation=\"relu\")(x)\n",
    "    ff_output = Dropout(dropout)(ff_output)\n",
    "    ff_output = Dense(inputs.shape[-1])(ff_output)\n",
    "    x = Add()([ff_output, x])\n",
    "    return x\n",
    "\n",
    "# Build a multi-input Transformer model\n",
    "def build_transformer_with_type_model(num_types, input_shape=(300, 300, 3), num_classes=4):\n",
    "    # Image input\n",
    "    image_input = Input(shape=input_shape, name='image_input')\n",
    "    \n",
    "    # Pre-trained EfficientNet as feature extractor\n",
    "    base_model = EfficientNetB0(include_top=False, input_tensor=image_input, weights=\"imagenet\")\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Use GlobalAveragePooling2D to reduce dimensions\n",
    "    image_features = GlobalAveragePooling2D()(base_model.output)\n",
    "    # Flatten the features\n",
    "    image_features = Flatten()(image_features)\n",
    "    \n",
    "    # Type input\n",
    "    type_input = Input(shape=(1,), name='type_input')\n",
    "    # Embedding for types\n",
    "    type_embedding = Embedding(input_dim=num_types, output_dim=8)(type_input)\n",
    "    # Flatten embedded features\n",
    "    type_features = Flatten()(type_embedding)\n",
    "    \n",
    "    # Combine image and type features\n",
    "    combined_features = Concatenate()([image_features, type_features])\n",
    "    # Reshape to three-dimensional tensor to fit MultiHeadAttention\n",
    "    reshaped_features = Reshape((1, -1))(combined_features)\n",
    "\n",
    "    # Add Transformer encoder layer\n",
    "    transformer_output = transformer_encoder(reshaped_features, head_size=256, num_heads=4, ff_dim=1024, dropout=0.1)\n",
    "    \n",
    "    # Remove sequence dimension as we only have one sequence\n",
    "    # This changes the shape of the output from (None, 1, 1288) to (None, 1288)\n",
    "    transformer_output = Flatten()(transformer_output)\n",
    "    # Classification head\n",
    "    classification_output = Dense(num_classes, activation='softmax')(transformer_output)\n",
    "    \n",
    "    # Create the model\n",
    "    model = Model(inputs=[image_input, type_input], outputs=classification_output)\n",
    "    \n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Model parameters\n",
    "input_shape = (300, 300, 3)  # Adjust to actual image size and channels\n",
    "num_classes = 4  # Number of classes\n",
    "\n",
    "# Create model\n",
    "model = build_transformer_with_type_model(num_types, input_shape, num_classes)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    [X_train, types_encoded.reshape(-1, 1)],  # Ensure type input is the correct shape\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=8,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('../models/transformer_with_type_aug_model.h5')\n",
    "\n",
    "# Visualize the model structure\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ca_tfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
